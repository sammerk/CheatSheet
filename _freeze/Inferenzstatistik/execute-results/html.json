{
  "hash": "c78cf221543b9231d0c86df94ca63991",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Inferenz- und Deskriptivstatistik\"\nformat:\n  live-html:\n    css: \n      - brand.css     \n      - exams/webex.css\n    include-after-body: exams/webex.js\nengine: knitr\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n\nDeskriptivstatistiken machen Aussagen über vorliegende Datensätze. Sie beschreiben also einen Datensatz und nichts darüber hinaus. Inferenzstatistiken machen dagegen Aussagen über (hypothetische) Mechanismen, die Daten erzeugen. Berechnet man z.B. den Mittelwert der Pinguinschnabellängen je Species im `palmerpenguins` Datensatz so handelt es sich um eine deskriptive Statistik. Möchte man wissen, um wie viel sich die Schnabellänge **im Durchschnitt** zwischen den Species (hypothetische Entität, Population) unterscheidet, handelt es sich um eine inferenzstatistische Fragestellung.\n\n::: callout-tip\n### Beispiele für Deskriptiv- und Inferenzstatistiken\n\n-   Deskriptivstatistiken\n    -   Median aller Massen von Pinguinen der Species Adelie im `palmerpenguins` Datensatz\n    -   Standardabweichung aller Körperlängen von Kalokokrebsen in einer Falle\n    -   Modus der Species in einem Datensatz von 200 Pflanzen\n-   Inferenzstatistiken\n    -   Zeigt eine Münze von 30 Würfen 16 mal Kopf, wie wahrscheinlich ist es dann, dass die Münze sehr klar gezinkt $\\left(\\theta > .55\\right)$ ist?«\n    -   Geben von 100 zufällig ausgewählten Waldkindergartenkindern 73 und von 100 zufällig ausgewählten Nicht-Waldkindergartenkindern 62 an, gerne mit Matsch zu spielen, wie sicher liegt dann ein Unterschied in der Zustimmung bei allen Kindergartenkindern vor\n    -   Zeigt sich in einer Stichprobe mit $N=124$ zwischen »Biodiversitätsbewusstsein« und »Biodiversitätswissen« ein standardisierter Regressionskoeffizient von $\\beta = .48$ -- wie wahrscheinlich liegt dann in der Population nur ein kleiner Effekt $\\beta < .1$ vor?\n:::\n\n## Parameterschätzung vs. Hypothesentestung\n\nTypischerweise wird bei der Inferenzstatistik zwischen *Parameterschätzung* und *Hypothesentests* unterschieden. Beide Ansätze können sowohl im Rahmen der frequentistischen als auch der bayesianischen Statistik durchgeführt werden. Mit Abstand am bekanntesten sind dabei die frequentistischen Hypothesentests mit *p*-Werten obwohl diese als sehr fehleranfällig in der Interpretation gelten [@gigerenzer2004].\n\n|   | Frequentistische<br>Statistik | Bayesianische<br>Statistik |\n|----------------------|:---------------------:|:-------------------------:|\n| Parameterschätzung | Konfidenzintervalle | Posterior Distributions |\n| Hypothesentest | p-Werte | Bayes Faktoren |\n\n<br>\n\n> (Inferenzstatistische) *Schätzung* (estimation with quantified uncertainty) trifft anhand von Stichproben Aussagen über Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.\n\n> (Inferenzstatistische) *Hypothesentests* bewerten anhand von Stichprobendaten die Gültigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.\n\n## Hypothesentests mit *p*-Werten\nFür das inferenzstatistische Hypothesentesten wird in der Regel ein Framework von Neyman & Pearson angewendet, das auf der Formulierung von zwei konkurrierenden Hypothesen (Nullhypothese und Alternativhypothese) basiert, dann anhand von Daten einen p-Wert berechnet und schließlich eine Entscheidung zwischen den beiden Hypothesen trifft [@neyman1928use].\nDer *p*-Wert ist dabei wie folgt definiert:\n\n$$\\text{p-Wert}= P\\left(\\text{vorl. o. extremer gegen }H_0\\text{ sprechende Daten} | H_0 \\text{ist wahr}\\right)$$\n\nDas bedeutet, dass der *p*-Wert die Wahrscheinlichkeit der vorliegenden Daten angibt, unter der Annahme, dass die Nullhypothese wahr ist. Fällt dieser p-Wert unter ein vorher festgelegtes Signifikanzlevel (z.B. $\\alpha = .05$), wird die Nullhypothese zugunsten der Alternativhypothese verworfen. \n\nNatürlich können auch mit dieser Prozedur Fehler gemacht werden. So kann es passieren, dass die Nullhypothese verworfen wird obwohl sie wahr ist (False Positve, Fehler 1. Art, $\\alpha$-Fehler) oder dass die Nullhypothese beibehalten wird obwohl die Alternativhypothese wahr ist (False Negative, Fehler 2. Art, $\\beta$-Fehler).\n\n|  | $H_0$ wird beibehalten | $H_0$ wird verworfen |\n|---|:---:|:---:|\n| **$H_0$ ist wahr** | ✓ Korrekte Entscheidung | ✗ Fehler 1. Art<br>($\\alpha$-Fehler, False Positive) |\n| **$H_1$ ist wahr** | ✗ Fehler 2. Art<br>($\\beta$-Fehler, False Negative) | ✓ Korrekte Entscheidung<br>(Power = $1-\\beta$) |\n\n<br>\n\n::: callout-tip\n### Beispiel: Hypothesentest mit p-Wert\nInteressiert sich beispielsweise eine Umweltpolitikerin dafür, ob es in Deutschland eine Mehrheit für ein Tempolimit von 120 km/h auf Autobahnen gibt, könnte sie alle Bürger:innen befragen und eine Deskriptivstatistik berechnen oder eine Stichprobe ziehen und den folgenden Hypothesentest durchführen:\n\n* Hypothesen \n    * Nullhypothese: *Der Anteil von Befürworter:innen und Gegner:innen eines Tempolimits von 120 km/h ist gleich groß: $\\theta_{für} = \\theta_{gegen} = .5$*<br>\n    * Alternativhypothese: *Es gibt eine Mehrheit für oder gegen das Tempolimit $\\theta_{für} \\neq \\theta_{gegen}$*\n\nAngenommen sie erhält die folgenden Daten aus einer Umfrage mit 4 zufällig ausgewählten Personen:\n\n* Daten: \n    * 1 gegen Tempolimit ✗\n    * 3 für Tempolimit ✓\n\nDann kann der *p*-Wert berechnet werden, also die Wahrscheinlichkeit, dass unter der Annahme der Nullhypothese (Anteil der Befürworter:innen = 50%) in einer Stichprobe von 4 Personen mindestens 3 Befürworter:innen auftreten:\n\n```{mermaid}\n%%{init: {\n  \"flowchart\": {\n    \"nodeSpacing\": 20,\n    \"rankSpacing\": 25\n  },\n  \"themeVariables\": {\n    \"fontSize\": \"10px\"\n  }\n}}%%\n\nflowchart LR\n  A([▶])\n\n  A -->|0.5| B([✓])\n  A -->|0.5| C([✗])\n\n  B -->|0.5| D([✓✓])\n  B -->|0.5| E([✓✗])\n  C -->|0.5| F([✗✓])\n  C -->|0.5| G([✗✗])\n\n  D -->|0.5| H([✓✓✓])\n  D -->|0.5| I([✓✓✗])\n  E -->|0.5| J([✓✗✓])\n  E -->|0.5| K([✓✗✗])\n  F -->|0.5| L([✗✓✓])\n  F -->|0.5| M([✗✓✗])\n  G -->|0.5| N([✗✗✓])\n  G -->|0.5| O([✗✗✗])\n\n  H -->|0.5| P([✓✓✓✓])\n  H -->|0.5| Q([✓✓✓✗])\n  I -->|0.5| R([✓✓✗✓])\n  I -->|0.5| S([✓✓✗✗])\n  J -->|0.5| T([✓✗✓✓])\n  J -->|0.5| U([✓✗✓✗])\n  K -->|0.5| V([✓✗✗✓])\n  K -->|0.5| W([✓✗✗✗])\n  L -->|0.5| X([✗✓✓✓])\n  L -->|0.5| Y([✗✓✓✗])\n  M -->|0.5| Z([✗✓✗✓])\n  M -->|0.5| AA([✗✓✗✗])\n  N -->|0.5| AB([✗✗✓✓])\n  N -->|0.5| AC([✗✗✓✗])\n  O -->|0.5| AD([✗✗✗✓])\n  O -->|0.5| AE([✗✗✗✗])\n\n  %% Farbdefinition für mindestens drei ✗\n  classDef manyNo fill:#d77d00,color:#000,stroke:#333;\n\n  class P,Q,R,T,W,X,AA,AC,AD,AE manyNo\n\n```\n\nDie Wahrscheinlichkeit für die Daten (höchstens 1 Befürworter:in, ✓) gegeben die Nullhypothese $\\left(\\theta = .5\\right)$ beträgt dabei $p = \\color{#d77d00}{10} \\cdot 0.5^4 = 0.625$\n\n\nDa der p-Wert von 0.625 größer als das Signifikanzlevel von 0.05 ist, ist das Ergebnis inkonklusiv, was bei einer so kleinen Stichprobe wenig überraschend ist.\nIm folgenden Codefenster kann der p-Wert auch mit R berechnet werden. Dazu kann man die Funktion `binom.test()` verwenden, die einen binomialen Hypothesentest durchführt. Sie hat die Argumente `x` (Anzahl der Erfolge, hier Befürworter:innen), `n` (Anzahl der Versuche, hier Befragte), `p` (hypothetische Quote) und `alternative` (Form der Alternativhypothese) mit den Optionen `less`, `greater` (einseitige Tests) und `two.sided` (zweiseitiger Test).\n\n1) Prüfen Sie, ob auch Sie auf einen p-Wert von 0.625 kommen.\n2) Suchen Sie Zahlenbeispiele, die zu einem *signifikanten* Ergebnis führen $\\left(p < \\alpha \\right)$.\n\n\n::: {.cell exercise='binomtest'}\n\n```{.webr .cell-code}\nbinom.test(x = 3, n = 4, alternative = \"two.sided\")\n```\n:::\n\n\n::: { .hint exercise=\"binomtest\"}\nSignifikant heißt ja, dass der p-Wert kleiner als 0.05 ist. Da unsere Nullhypothese ja *Der Anteil der Befürworter:innen eines Tempolimits von 120 km/h ≥ 50%* lautet, brauchen wir also Daten, die stark gegen diese Hypothese sprechen.\n:::\n\n::: { .solution exercise=\"binomtest\"}\n`binom.test(x = 4000, n = 4321, alternative = \"two.sided\")`\n:::\n\n:::\n\nJe nachdem, welche Hypothesen mit welcher Art von Daten formuliert werden, muss der *p*-Wert unterschiedlich berechnet werden, was in den meisten Fällen über spezialisierte statistische Tests geschieht (z.B. t-Test, ANOVA, Chi-Quadrat-Test, etc.), deren mathematische Grundlagen recht komplex sind.\nDie grundlegende Idee bleibt dabei aber immer gleich: Es wird eine Nullhypothese formuliert, die Wahrscheinlichkeit der vorliegenden Daten unter der Annahme der Nullhypothese berechnet und dann eine Entscheidung über die Gültigkeit der Nullhypothese getroffen.\nÜbersichten, welche Tests für welche Daten und Hypothesen zur Berechnung von p-Werten geeignet sind, finden sich in vielen Statistikbüchern und Online-Ressourcen [z.B. @field2014].\n\n## Parameterschätzung mit Konfidenzintervallen\nLeider werden Hypothesentest mit p-Werten oft in einer recht wenig informativen Art und Weise eingesetzt: So wird oft nur berichtet, ob ein Ergebnis »signifikant« ist oder nicht, ohne dass die tatsächliche Größe des Effekts oder die Unsicherheit der Schätzung berücksichtigt wird. Dies kann zu Fehlinterpretationen und falschen Schlussfolgerungen führen [@cumming2014].\nEine Alternative zu Hypothesentests mit p-Werten ist die Parameterschätzung mit Konfidenzintervallen. Anstatt mit dem p-Wert die Wahrscheinlichkeit der Daten unter der Nullhypothese auszudrücken, wird mit Konfidenzintervallen die Unsicherheit der Schätzung eines Parameters von Interesse (z.B. Quote, Mittelwert, Regressionskoeffizient) angegeben. \nFührt man etwa den binomialen Test aus dem obigen Beispiel durch,\n\n::: {.cell}\n\n```{.r .cell-code}\nbinom.test(x = 1, n = 4, conf.level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tExact binomial test\n\ndata:  1 and 4\nnumber of successes = 1, number of trials = 4, p-value = 0.625\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.006309463 0.805879550\nsample estimates:\nprobability of success \n                  0.25 \n```\n\n\n:::\n:::\n\nso erhält man auch Auskunft, dass das Konfidenzintervall für die Quote der Befürworter:innen von 0.0000 bis 0.6410 reicht. Das bedeutet allerdings nicht, dass wir mit 95%iger Sicherheit sagen können, dass der wahre Anteil der Befürworter:innen in der Population irgendwo zwischen 0% und 64.1% liegt. Vielmehr bedeutet es, dass wenn wir unendlich viele Stichproben ziehen und für jede Stichprobe ein 95%-Konfidenzintervall berechnen würden, dann würden 95% dieser Intervalle den wahren Populationsparameter enthalten wie die folgende Animation veranschaulicht.\n\n```{=html}\n<iframe width=\"100%\" height=\"900\" src=\"ci_visualization.html\" title=\"KI Visualisierung\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n```",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}